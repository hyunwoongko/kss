# Kss: A Toolkit for Korean sentence segmentation
<a href="https://github.com/hyunwoongko/kss/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/hyunwoongko/kss.svg" /></a>
<a href="https://github.com/hyunwoongko/kss/issues"><img alt="Issues" src="https://img.shields.io/github/issues/hyunwoongko/kss"/></a>

This repository contains the source code of Kss, a representative Korean sentence segmentation toolkit. I also conduct ongoing research about Korean sentence segmentation algorithms and report the results to this repository.
If you have some good ideas about Korean sentence segmentation, please feel free to talk through the [issue](https://github.com/hyunwoongko/kss/issues).

<br>

### What's New:
- December 19, 2022 [Released Kss 4.0 Python](https://github.com/hyunwoongko/kss/releases/tag/4.0.0).
- May 5, 2022 [Released Kss Fluter](https://github.com/khjde1207/kss_dart).
- August 25, 2021 [Released Kss Java](https://github.com/sangdee/kss-java).
- August 18, 2021 [Released Kss 3.0 Python](https://github.com/hyunwoongko/kss/releases/tag/3.0.1).
- December 21, 2020 [Released Kss 2.0 Python](https://github.com/hyunwoongko/kss/releases/tag/3.0.1).
- August 16, 2019 [Released Kss 1.0 C++](https://github.com/hyunwoongko/kss/releases/tag/3.0.1).

## Installation
### Install Kss
Kss can be easily installed using the pip package manager.
```console
pip install kss
```

### Install Mecab (Optional)
Please install one of mecab, konlpy.tag.Mecab to use Kss much faster.
- mecab (Linux/MacOS): https://github.com/hyunwoongko/python-mecab-kor
- mecab (Windows): https://cleancode-ws.tistory.com/97
- konlpy.tag.Mecab (Linux/MacOS): https://konlpy.org/en/latest/api/konlpy.tag/#mecab-class
- konlpy.tag.Mecab (Windows): https://uwgdqo.tistory.com/363

## Features

#### 1) `split_sentences`: split text into sentences

```python
from kss import split_sentences

split_sentences(
    text: Union[str, List[str], Tuple[str]],
    backend: str = "auto",
    num_workers: Union[int, str] = "auto" 
)
```

<details>
<summary>Parameters</summary>

- **text: String or List/Tuple of strings**
    - string: single text segmentation
    - list/tuple of strings: batch texts segmentation
- **backend: Morpheme analyzer backend.**
    - `backend='auto'`: find `mecab` â†’ `konlpy.tag.Mecab` â†’ `pecab` and use first found analyzer (default)
    - `backend='mecab'`: find `mecab` â†’ `konlpy.tag.Mecab` and use first found analyzer
    - `backend='pecab'`: use `pecab` analyzer
- **num_workers: The number of multiprocessing workers.**
    - `num_workers='auto'`: use multiprocessing with the maximum number of workers if possible (default)
    - `num_workers=1`: don't use multiprocessing
    - `num_workers=2~N`: use multiprocessing with the specified number of workers

</details>

<details>
<summary>Usages</summary>

- Single text segmentation
  ```python
  import kss

  text = "íšŒì‚¬ ë™ë£Œ ë¶„ë“¤ê³¼ ë‹¤ë…€ì™”ëŠ”ë° ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ìŒì‹ë„ ë§›ìˆì—ˆì–´ìš” ë‹¤ë§Œ, ê°•ë‚¨ í† ë¼ì •ì´ ê°•ë‚¨ ì‰‘ì‰‘ë²„ê±° ê³¨ëª©ê¸¸ë¡œ ì­‰ ì˜¬ë¼ê°€ì•¼ í•˜ëŠ”ë° ë‹¤ë“¤ ì‰‘ì‰‘ë²„ê±°ì˜ ìœ í˜¹ì— ë„˜ì–´ê°ˆ ë»” í–ˆë‹µë‹ˆë‹¤ ê°•ë‚¨ì—­ ë§›ì§‘ í† ë¼ì •ì˜ ì™¸ë¶€ ëª¨ìŠµ."

  kss.split_sentences(text)
  # ['íšŒì‚¬ ë™ë£Œ ë¶„ë“¤ê³¼ ë‹¤ë…€ì™”ëŠ”ë° ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ìŒì‹ë„ ë§›ìˆì—ˆì–´ìš”', 'ë‹¤ë§Œ, ê°•ë‚¨ í† ë¼ì •ì´ ê°•ë‚¨ ì‰‘ì‰‘ë²„ê±° ê³¨ëª©ê¸¸ë¡œ ì­‰ ì˜¬ë¼ê°€ì•¼ í•˜ëŠ”ë° ë‹¤ë“¤ ì‰‘ì‰‘ë²„ê±°ì˜ ìœ í˜¹ì— ë„˜ì–´ê°ˆ ë»” í–ˆë‹µë‹ˆë‹¤', 'ê°•ë‚¨ì—­ ë§›ì§‘ í† ë¼ì •ì˜ ì™¸ë¶€ ëª¨ìŠµ.']
  ```

- Batch texts segmentation
  ```python
  import kss

  texts = [
      "íšŒì‚¬ ë™ë£Œ ë¶„ë“¤ê³¼ ë‹¤ë…€ì™”ëŠ”ë° ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ìŒì‹ë„ ë§›ìˆì—ˆì–´ìš” ë‹¤ë§Œ, ê°•ë‚¨ í† ë¼ì •ì´ ê°•ë‚¨ ì‰‘ì‰‘ë²„ê±° ê³¨ëª©ê¸¸ë¡œ ì­‰ ì˜¬ë¼ê°€ì•¼ í•˜ëŠ”ë° ë‹¤ë“¤ ì‰‘ì‰‘ë²„ê±°ì˜ ìœ í˜¹ì— ë„˜ì–´ê°ˆ ë»” í–ˆë‹µë‹ˆë‹¤",
      "ê°•ë‚¨ì—­ ë§›ì§‘ í† ë¼ì •ì˜ ì™¸ë¶€ ëª¨ìŠµ. ê°•ë‚¨ í† ë¼ì •ì€ 4ì¸µ ê±´ë¬¼ ë…ì±„ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.",
      "ì—­ì‹œ í† ë¼ì • ë³¸ ì  ë‹µì£ ?ã…ã……ã… ê±´ë¬¼ì€ í¬ì§€ë§Œ ê°„íŒì´ ì—†ê¸° ë•Œë¬¸ì— ì§€ë‚˜ì¹  ìˆ˜ ìˆìœ¼ë‹ˆ ì¡°ì‹¬í•˜ì„¸ìš” ê°•ë‚¨ í† ë¼ì •ì˜ ë‚´ë¶€ ì¸í…Œë¦¬ì–´.",
  ]

  kss.split_sentences(texts)
  # [['íšŒì‚¬ ë™ë£Œ ë¶„ë“¤ê³¼ ë‹¤ë…€ì™”ëŠ”ë° ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ìŒì‹ë„ ë§›ìˆì—ˆì–´ìš”', 'ë‹¤ë§Œ, ê°•ë‚¨ í† ë¼ì •ì´ ê°•ë‚¨ ì‰‘ì‰‘ë²„ê±° ê³¨ëª©ê¸¸ë¡œ ì­‰ ì˜¬ë¼ê°€ì•¼ í•˜ëŠ”ë° ë‹¤ë“¤ ì‰‘ì‰‘ë²„ê±°ì˜ ìœ í˜¹ì— ë„˜ì–´ê°ˆ ë»” í–ˆë‹µë‹ˆë‹¤']
  # ['ê°•ë‚¨ì—­ ë§›ì§‘ í† ë¼ì •ì˜ ì™¸ë¶€ ëª¨ìŠµ.', 'ê°•ë‚¨ í† ë¼ì •ì€ 4ì¸µ ê±´ë¬¼ ë…ì±„ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.']
  # ['ì—­ì‹œ í† ë¼ì • ë³¸ ì  ë‹µì£ ?ã…ã……ã…', 'ê±´ë¬¼ì€ í¬ì§€ë§Œ ê°„íŒì´ ì—†ê¸° ë•Œë¬¸ì— ì§€ë‚˜ì¹  ìˆ˜ ìˆìœ¼ë‹ˆ ì¡°ì‹¬í•˜ì„¸ìš”', 'ê°•ë‚¨ í† ë¼ì •ì˜ ë‚´ë¶€ ì¸í…Œë¦¬ì–´.']]
  ```

</details>

<details>
<summary>Performance Analysis</summary>

#### 1) Test Commands
You can reproduce this experiment using source code and datasets in `./bench/` directory and the source code was copied from [here](https://github.com/bab2min/kiwipiepy/tree/main/benchmark/sentence_split).
Note that the `Baseline` is regex based segmentation like `re.split(r"(?<=[.!?])\s", text)`.

| Name                                             | Command (in root directory)                                                                               |
|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------|
| Baseline                                         | `python3 ./bench/test_baseline.py ./bench/testset/*.txt`                                                  |
| [Kiwi](https://github.com/bab2min/kiwipiepy)     | `python3 ./bench/test_kiwi.py ./bench/testset/*.txt`                                                      |
| [Koalanlp](https://github.com/koalanlp/koalanlp) | `python3 ./bench/test_koalanlp.py ./bench/testset/*.txt --backend=OKT/HNN/KMR/RHINO/EUNJEON/ARIRANG/KAMA` |
| [Kss](https://github.com/hyunwoongko/kss) (ours) | `python3 ./bench/test_kss.py ./bench/testset/*.txt --backend=mecab/pecab`                                 |

<br>

#### 2) Evaluation datasets:

I tested it using the following 6 evaluation datasets. Thanks to [Minchul Lee](https://github.com/bab2min) for creating various sentence segmentation datasets.

| Name                                                                                  | Descriptions                                                                              | The number of sentences | Creator                                                                                                                                                                                                                                                            |
|---------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|-------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [blogs_lee](https://github.com/hyunwoongko/kss/blob/main/bench/testset/blogs_lee.txt) | Dataset for testing blog style text segmentation                                          | 170                     | [Minchul Lee](https://github.com/bab2min/kiwipiepy/tree/main/benchmark/sentence_split)                                                                                                                                                                             |
| [blogs_ko](https://github.com/hyunwoongko/kss/blob/main/bench/testset/blogs_ko.txt)   | Dataset for testing blog style text segmentation, which is harder than Lee's blog dataset | 336                     | [Hyunwoong Ko](https://github.com/hyunwoongko)                                                                                                                                                                                                                     |
| [tweets](https://github.com/hyunwoongko/kss/blob/main/bench/testset/tweets.txt)       | Dataset for testing tweeter style text segmentation                                       | 178                     | [Minchul Lee](https://github.com/bab2min/kiwipiepy/tree/main/benchmark/sentence_split)                                                                                                                                                                             |
| [nested](https://github.com/hyunwoongko/kss/blob/main/bench/testset/nested.txt)       | Dataset for testing text which have parentheses and quotation marks segmentation          | 91                      | [Minchul Lee](https://github.com/bab2min/kiwipiepy/tree/main/benchmark/sentence_split)                                                                                                                                                                             |
| [v_ending](https://github.com/hyunwoongko/kss/blob/main/bench/testset/v_ending.txt)   | Dataset for testing difficult eomi segmentation, it contains various dialect sentences    | 30                      | [Minchul Lee](https://github.com/bab2min/kiwipiepy/tree/main/benchmark/sentence_split)                                                                                                                                                                             |
| [sample](https://github.com/hyunwoongko/kss/blob/main/bench/testset/sample.txt)       | An example used in README.md (ê°•ë‚¨ í† ë¼ì •)                                                     | 41                      | [Isaac](http://semantics.kr/%ed%95%9c%ea%b5%ad%ec%96%b4-%ed%98%95%ed%83%9c%ec%86%8c-%eb%b6%84%ec%84%9d%ea%b8%b0-%eb%b3%84-%eb%ac%b8%ec%9e%a5-%eb%b6%84%eb%a6%ac-%ec%84%b1%eb%8a%a5%eb%b9%84%ea%b5%90/), modified by [Hyunwoong Ko](https://github.com/hyunwoongko) |

Note that I modified labels of two sentences in `sample.txt` made by [Issac](http://semantics.kr/%ed%95%9c%ea%b5%ad%ec%96%b4-%ed%98%95%ed%83%9c%ec%86%8c-%eb%b6%84%ec%84%9d%ea%b8%b0-%eb%b3%84-%eb%ac%b8%ec%9e%a5-%eb%b6%84%eb%a6%ac-%ec%84%b1%eb%8a%a5%eb%b9%84%ea%b5%90/)
because the [original blog post](https://blog.naver.com/jully1211/221437777873) was written like the following:

<img width=1000px src="https://github.com/hyunwoongko/kss/blob/main/assets/rabbit_1.png">

<img width=1000px src="https://github.com/hyunwoongko/kss/blob/main/assets/rabbit_2.png">

But Issac's labels were:

<img width=500px src="https://github.com/hyunwoongko/kss/blob/main/assets/issac.png">

In fact, `ì‚¬ì‹¤ ì „ ê³ ê¸°ë¥¼ ì•ˆ ë¨¹ì–´ì„œ ë¬´ìŠ¨ ë§›ì¸ì§€ ëª¨ë¥´ê² ì§€ë§Œ..` and `(ë¬¼ë¡  ì „ ì•ˆ ë¨¹ì—ˆì§€ë§Œ` are adverb clauses (ë¶€ì‚¬ì ˆ), not independent sentences (ë¬¸ì¥).
So I corrected labels of the two sentences.

<br>

#### 3) Sentence segmentation performance (Quantitative Analysis)
 
The following table shows the segmentation performance based on **exact match method**.
Kss performed best in most cases, and Kiwi performed well. Both baseline and koalanlp performed poorly.

| Name           | Library version | Backend | blogs_lee   | blogs_ko    | tweets      | nested      | v_ending    | sample      | Average     |
|----------------|-----------------|---------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| Baseline       | N/A             | N/A     | 0.53529     | 0.44940     | 0.51124     | 0.68132     | 0.00000     | 0.34146     | 0.41987     |
| Koalanlp       | 2.1.7           | OKT     | 0.53529     | 0.44940     | 0.53371     | 0.79121     | 0.00000     | 0.36585     | 0.44591     |
| Koalanlp       | 2.1.7           | HNN     | 0.54118     | 0.44345     | 0.54494     | 0.78022     | 0.00000     | 0.34146     | 0.44187     |
| Koalanlp       | 2.1.7           | KMR     | 0.51176     | 0.39583     | 0.42135     | 0.79121     | 0.00000     | 0.26829     | 0.39807     |
| Koalanlp       | 2.1.7           | RHINO   | 0.52941     | 0.40774     | 0.39326     | 0.79121     | 0.00000     | 0.29268     | 0.40238     |
| Koalanlp       | 2.1.7           | EUNJEON | 0.51176     | 0.37500     | 0.38202     | 0.70330     | 0.00000     | 0.21951     | 0.36526     |
| Koalanlp       | 2.1.7           | ARIRANG | 0.51176     | 0.41071     | 0.44382     | 0.79121     | 0.00000     | 0.29268     | 0.40836     |
| Koalanlp       | 2.1.7           | KKMA    | 0.52941     | 0.45238     | 0.38202     | 0.58242     | 0.06667     | 0.31707     | 0.38832     |
| Kiwi           | 0.14.0          | N/A     | 0.78235     | 0.60714     | 0.66292     | 0.83516     | 0.20000     | 0.90244     | 0.66500     |
| **Kss (ours)** | 4.0.0           | pecab   | **0.86471** | **0.82440** | 0.71910     | **0.87912** | **0.36667** | **0.95122** | 0.76753     |
| **Kss (ours)** | 4.0.0           | mecab   | **0.86471** | **0.82440** | **0.73034** | **0.87912** | **0.36667** | **0.95122** | **0.76941** |

You can also compare the performances with the following graphs.

![](https://github.com/hyunwoongko/kss/blob/main/assets/tasks_performance.png)

![](https://github.com/hyunwoongko/kss/blob/main/assets/average_score.png)

<br>

#### 4) Why don't I trust F1 score?
The evaluation source code which I copied from [kiwipiepy](https://github.com/bab2min/kiwipiepy/tree/main/benchmark/sentence_split) also provides F1 score  (dice similarity), 
but I don't believe this is proper metric to measure sentence segmentation performance.
For example, EM score of `text.split(" ")` on `tweets.txt` is 0.06742. This means it's terrible sentence segmentation method on tweeter style text.
However, F1 score of it on `tweets.txt` is 0.54083, and it is similar with the F1 score of Koalanlp KKMA backend (0.56832).

What I want to say is the F1 scores were similar but the performances of segmentation are hugely different.
You can reproduce this with `python3 ./bench/test_word_split.py ./bench/testset/tweets.txt`, and here is one of the segmentation example of both method.

```
Input:

ê¸°ì–µí•´. ë„Œ ê·¸ ì• ì˜ ì¹œêµ¬ì•¼. ë„¤ê°€ ì£½ìœ¼ë©´ ë§ˆ ë“¤ë ˆ ëŠê°€ í‘í‘ ìš¸ ê±°ì•¼. ë¹„ ì²´ëŠ” ìŠ¬í¼í•˜ê² ì§€. ì´ ì•ˆì€ í™”ë¥¼ ë‚¼ ê±°ì•¼. ë©”ì´ ì‹œëŠ” ì–´ì©Œë©´ ì¡°ê¸ˆì€ ìƒê° í•´ ì£¼ì§€ ì•Šì„ê¹Œ. ì¤‘ìš”í•œ ê±´ ê·¸ê±´ ë„¤ê°€ ì§€í‚¤ê³  ì‹¶ì–´ í–ˆë˜ ì‚¬ëŒë“¤ì´ì–ì•„. ì–´ì„œ ê°€.
```
```
Method: Koalanlp KKMA backend
EM score: 0.38202
F1 score: 0.56832

Output:
ê¸°ì–µí•´. ë„Œ ê·¸ ì• ì˜ ì¹œêµ¬ì•¼.
ë„¤ê°€ ì£½ìœ¼ë©´ ë§ˆ ë“¤ë ˆ ëŠê°€ í‘í‘ ìš¸ ê±°ì•¼.
ë¹„ ì²´ëŠ” ìŠ¬í¼í•˜ê² ì§€.
ì´ ì•ˆì€ í™”ë¥¼ ë‚¼ ê±°ì•¼.
ë©”ì´ ì‹œëŠ” ì–´ì©Œë©´ ì¡°ê¸ˆì€ ìƒê° í•´ ì£¼ì§€ ì•Šì„ê¹Œ.
ì¤‘ìš”í•œ ê±´ ê·¸ê±´ ë„¤ê°€ ì§€í‚¤ê³  ì‹¶ì–´ í–ˆë˜ ì‚¬ëŒë“¤ì´ì–ì•„.
ì–´ì„œ ê°€.
```

```
Method: text.split(" ")
EM score: 0.06742
F1 score: 0.54083

Output:
ê¸°ì–µí•´.
ë„Œ
ê·¸
ì• ì˜
ì¹œêµ¬ì•¼.
ë„¤ê°€
ì£½ìœ¼ë©´
ë§ˆë“¤ë ˆëŠê°€
í‘í‘
ìš¸ê±°ì•¼.
ë¹„ì²´ëŠ”
ìŠ¬í¼í•˜ê² ì§€.
ì´ì•ˆì€
í™”ë¥¼
ë‚¼ê±°ì•¼.
ë©”ì´ì‹œëŠ”
ì–´ì©Œë©´
ì¡°ê¸ˆì€
ìƒê°
í•´ì£¼ì§€
ì•Šì„ê¹Œ.
ì¤‘ìš”í•œê±´
ê·¸ê±´
ë„¤ê°€
ì§€í‚¤ê³ 
ì‹¶ì–´í–ˆë˜
ì‚¬ëŒë“¤ì´ì–ì•„.
ì–´ì„œ
ê°€.
```

This means that the F1 score has the advantages for method that cut too finely.
Of course, measuring the performance of the sentence segmentation algorithm is difficult, and we need to think more about metrics. 
However, the character level F1 score may cause **users to misunderstand the tool's real performance**. 
So I have more confidence in the EM score, which is a somewhat clunky but safe metric.

<br>

#### 5) Where does the difference in performance come from? (Qualitative Analysis)
It is meaningless to simply compare them by number. I definitely want you to see the segmentation results.
Let's take `blogs_ko` samples as examples, and compare performance of each library.
For this, I will take the best backend of each library (Kss=mecab, Koalanlp=KKMA), because looking results of all backends may make you tired.

#### Example 1
- Input text
```
ê±°ì œ ë‚´ë ¤ê°€ëŠ” ê¸¸ì— íœ´ê²Œì†Œë¥¼ ë“¤ë ¸ëŠ”ë° ìƒˆë¡œ ìƒê²¼ë‚˜ë³´ë”ë¼êµ¬ìš”!? ë‚¨í¸ê³¼ ì €, ë‘˜ ë‹¤ ë¹µëŸ¬ë²„ë¼ ì§€ë‚˜ì¹  ìˆ˜ ì—†ì–´ êµ¬ë§¤í•´ ë¨¹ì–´ë´¤ë‹µë‹ˆë‹¹ğŸ˜Š ë³´ì„±ë…¹ì°¨íœ´ê²Œì†Œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì‹œë©´ ë”± ê°€ìš´ë° ìœ„ì¹˜í•´ ìˆì–´ìš”ã…ã… ê·¸ë˜ì„œ ì–´ëŠ ë¬¸ìœ¼ë¡œë¼ë„ ë“¤ì–´ì˜¤ì…”ë„ ê°€ê¹ë‹µë‹ˆë‹¤ğŸ˜‰ ë©”ë‰´íŒì„ ì´ë ‡ê³ , ê°€ê²©ì€ 2000ì›~3000ì› ì‚¬ì´ì— í˜•ì„± ë˜ì–´ ìˆì–´ìš”! ì´ëŸ°ê±° í•˜ë‚˜í•˜ë‚˜ ë§›ë³´ëŠ”ê±° ë„ˆë¬´ ì¢‹ì•„í•˜ëŠ”ë°... ì§„ì •í•˜ê³  ì†Œë¯¸ë¯¸ ë‹¨íŒ¥ë¹µ í•˜ë‚˜, ì˜¥ìˆ˜ìˆ˜ ì¹˜ì¦ˆë¹µ í•˜ë‚˜, êµ¬ë¦¬ë³¼ í•˜ë‚˜ ê³¨ëìŠµë‹ˆë‹¤! ë‹¤ìŒì— ê°€ë©´ ê°•ë‚­ì½©ì´ë‘ ë°¤ ê¼­ ë¨¹ì–´ë´ì•¼ê² ì–´ìš”ğŸ˜™
```
- Label
```
ê±°ì œ ë‚´ë ¤ê°€ëŠ” ê¸¸ì— íœ´ê²Œì†Œë¥¼ ë“¤ë ¸ëŠ”ë° ìƒˆë¡œ ìƒê²¼ë‚˜ë³´ë”ë¼êµ¬ìš”!?
ë‚¨í¸ê³¼ ì €, ë‘˜ ë‹¤ ë¹µëŸ¬ë²„ë¼ ì§€ë‚˜ì¹  ìˆ˜ ì—†ì–´ êµ¬ë§¤í•´ ë¨¹ì–´ë´¤ë‹µë‹ˆë‹¹ğŸ˜Š
ë³´ì„±ë…¹ì°¨íœ´ê²Œì†Œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì‹œë©´ ë”± ê°€ìš´ë° ìœ„ì¹˜í•´ ìˆì–´ìš”ã…ã…
ê·¸ë˜ì„œ ì–´ëŠ ë¬¸ìœ¼ë¡œë¼ë„ ë“¤ì–´ì˜¤ì…”ë„ ê°€ê¹ë‹µë‹ˆë‹¤ğŸ˜‰
ë©”ë‰´íŒì„ ì´ë ‡ê³ , ê°€ê²©ì€ 2000ì›~3000ì› ì‚¬ì´ì— í˜•ì„± ë˜ì–´ ìˆì–´ìš”!
ì´ëŸ°ê±° í•˜ë‚˜í•˜ë‚˜ ë§›ë³´ëŠ”ê±° ë„ˆë¬´ ì¢‹ì•„í•˜ëŠ”ë°... ì§„ì •í•˜ê³  ì†Œë¯¸ë¯¸ ë‹¨íŒ¥ë¹µ í•˜ë‚˜, ì˜¥ìˆ˜ìˆ˜ ì¹˜ì¦ˆë¹µ í•˜ë‚˜, êµ¬ë¦¬ë³¼ í•˜ë‚˜ ê³¨ëìŠµë‹ˆë‹¤!
ë‹¤ìŒì— ê°€ë©´ ê°•ë‚­ì½©ì´ë‘ ë°¤ ê¼­ ë¨¹ì–´ë´ì•¼ê² ì–´ìš”ğŸ˜™
```
- Source
```
https://hi-e2e2.tistory.com/193
```
- Output texts
```
Baseline:

ê±°ì œ ë‚´ë ¤ê°€ëŠ” ê¸¸ì— íœ´ê²Œì†Œë¥¼ ë“¤ë ¸ëŠ”ë° ìƒˆë¡œ ìƒê²¼ë‚˜ë³´ë”ë¼êµ¬ìš”!?
ë‚¨í¸ê³¼ ì €, ë‘˜ ë‹¤ ë¹µëŸ¬ë²„ë¼ ì§€ë‚˜ì¹  ìˆ˜ ì—†ì–´ êµ¬ë§¤í•´ ë¨¹ì–´ë´¤ë‹µë‹ˆë‹¹ğŸ˜Š ë³´ì„±ë…¹ì°¨íœ´ê²Œì†Œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì‹œë©´ ë”± ê°€ìš´ë° ìœ„ì¹˜í•´ ìˆì–´ìš”ã…ã… ê·¸ë˜ì„œ ì–´ëŠ ë¬¸ìœ¼ë¡œë¼ë„ ë“¤ì–´ì˜¤ì…”ë„ ê°€ê¹ë‹µë‹ˆë‹¤ğŸ˜‰ ë©”ë‰´íŒì„ ì´ë ‡ê³ , ê°€ê²©ì€ 2000ì›~3000ì› ì‚¬ì´ì— í˜•ì„± ë˜ì–´ ìˆì–´ìš”!
ì´ëŸ°ê±° í•˜ë‚˜í•˜ë‚˜ ë§›ë³´ëŠ”ê±° ë„ˆë¬´ ì¢‹ì•„í•˜ëŠ”ë°...
ì§„ì •í•˜ê³  ì†Œë¯¸ë¯¸ ë‹¨íŒ¥ë¹µ í•˜ë‚˜, ì˜¥ìˆ˜ìˆ˜ ì¹˜ì¦ˆë¹µ í•˜ë‚˜, êµ¬ë¦¬ë³¼ í•˜ë‚˜ ê³¨ëìŠµë‹ˆë‹¤!
ë‹¤ìŒì— ê°€ë©´ ê°•ë‚­ì½©ì´ë‘ ë°¤ ê¼­ ë¨¹ì–´ë´ì•¼ê² ì–´ìš”ğŸ˜™
```

Baseline separated input text into five sentences because it is split when `.!?` (final symbols) appears.
First of all, the first sentence was well separated because the finish symbol appeared. However, since these symbols didn't appear well from the second sentence, you can see that they didn't separated.

```
Koalanlp (KKMA):

ê±°ì œ ë‚´ë ¤ê°€ëŠ” ê¸¸ì— íœ´ê²Œ ì†Œë¥¼ ë“¤ë ¸ëŠ”ë° ìƒˆë¡œ ìƒê²¼ë‚˜
ë³´ë”ë¼êµ¬ìš”!?
ë‚¨í¸ê³¼ ì €, ë‘˜ ë‹¤ ë¹µ ëŸ¬ë²„ë¼ ì§€ë‚˜ì¹  ìˆ˜ ì—†ì–´ êµ¬ë§¤í•´ ë¨¹ì–´ ë´¤ë‹µë‹ˆë‹¹
ğŸ˜Š ë³´ì„± ë…¹ì°¨ íœ´ê²Œì†Œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì‹œë©´ ë”± ê°€ìš´ë° ìœ„ì¹˜í•´ ìˆì–´ìš”
ã…ã… ê·¸ë˜ì„œ ì–´ëŠ ë¬¸ìœ¼ë¡œ ë¼ë„ ë“¤ì–´ì˜¤ì…”ë„ ê°€ê¹ë‹µë‹ˆë‹¤
ğŸ˜‰ ë©”ë‰´íŒì„ ì´ë ‡ê³ , ê°€ê²©ì€ 2000ì› ~3000 ì› ì‚¬ì´ì— í˜•ì„± ë˜ì–´ ìˆì–´ìš”!
ì´ëŸ° ê±° í•˜ë‚˜í•˜ë‚˜ ë§›ë³´ëŠ” ê±° ë„ˆë¬´ ì¢‹ì•„í•˜ëŠ”ë°... ì§„ì •í•˜ê³  ì†Œë¯¸ ë¯¸ ë‹¨íŒ¥ë¹µ í•˜ë‚˜, ì˜¥ìˆ˜ìˆ˜ ì¹˜ì¦ˆ ë¹µ í•˜ë‚˜, êµ¬ë¦¬ ë³¼ í•˜ë‚˜ ê³¨ëìŠµë‹ˆë‹¤!
ë‹¤ìŒì— ê°€ë©´ ê°•ë‚­ì½©ì´ë‘ ë°¤ ê¼­ ë¨¹ì–´ë´ì•¼ê² ì–´ìš”ğŸ˜™
```

Koalanlp separates them better than baseline because it uses morphological information. It divided input text into 8 sentences in total.
The first thing that catches your eye is the immature emoji handling. 
People usually put some emojis at the end of a sentence, and in this case, the emojis should be included in the sentence.
The second thing is the mispartition between `ìƒê²¼ë‚˜` and `ë³´ë”ë¼êµ¬ìš”!?`. 
Probably because the KKMA morpheme analyzer recognized that point as a final eomi (ì¢…ê²°ì–´ë¯¸). 
This is because the performance of the morpheme analyzer. 
Rather, the baseline is a little safer in this area.

```
Kiwi:

ê±°ì œ ë‚´ë ¤ê°€ëŠ” ê¸¸ì— íœ´ê²Œì†Œë¥¼ ë“¤ë ¸ëŠ”ë° ìƒˆë¡œ ìƒê²¼ë‚˜ë³´ë”ë¼êµ¬ìš”!?
ë‚¨í¸ê³¼ ì €, ë‘˜ ë‹¤ ë¹µëŸ¬ë²„ë¼ ì§€ë‚˜ì¹  ìˆ˜ ì—†ì–´ êµ¬ë§¤í•´ ë¨¹ì–´ë´¤ë‹µë‹ˆë‹¹ğŸ˜Š
ë³´ì„±ë…¹ì°¨íœ´ê²Œì†Œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì‹œë©´ ë”± ê°€ìš´ë° ìœ„ì¹˜í•´ ìˆì–´ìš”ã…ã…
ê·¸ë˜ì„œ ì–´ëŠ ë¬¸ìœ¼ë¡œë¼ë„ ë“¤ì–´ì˜¤ì…”ë„ ê°€ê¹ë‹µë‹ˆë‹¤ğŸ˜‰ ë©”ë‰´íŒì„ ì´ë ‡ê³ , ê°€ê²©ì€ 2000ì›~3000ì› ì‚¬ì´ì— í˜•ì„± ë˜ì–´ ìˆì–´ìš”!
ì´ëŸ°ê±° í•˜ë‚˜í•˜ë‚˜ ë§›ë³´ëŠ”ê±° ë„ˆë¬´ ì¢‹ì•„í•˜ëŠ”ë°...
ì§„ì •í•˜ê³  ì†Œë¯¸ë¯¸ ë‹¨íŒ¥ë¹µ í•˜ë‚˜, ì˜¥ìˆ˜ìˆ˜ ì¹˜ì¦ˆë¹µ í•˜ë‚˜, êµ¬ë¦¬ë³¼ í•˜ë‚˜ ê³¨ëìŠµë‹ˆë‹¤!
ë‹¤ìŒì— ê°€ë©´ ê°•ë‚­ì½©ì´ë‘ ë°¤ ê¼­ ë¨¹ì–´ë´ì•¼ê² ì–´ìš”ğŸ˜™
```
Kiwi shows better performance than Koalanlp. It divided input text into 7 sentences. 
Most sentences are pretty good, but it didn't separate between `ê°€ê¹ë‹µë‹ˆë‹¤ğŸ˜‰` and `ë©”ë‰´íŒì„`.
The second thing is it separates between `ì¢‹ì•„í•˜ëŠ”ë°...` and `ì§„ì •í•˜ê³ `.
This part may be recognized as an independent sentence depending on the viewer, 
but the author of the original article did not write this as a sentence.

The [original article](https://hi-e2e2.tistory.com/193) was written like:
    
![](https://github.com/hyunwoongko/kss/blob/main/assets/example_1_1.png)

```
Kss (mecab):

ê±°ì œ ë‚´ë ¤ê°€ëŠ” ê¸¸ì— íœ´ê²Œì†Œë¥¼ ë“¤ë ¸ëŠ”ë° ìƒˆë¡œ ìƒê²¼ë‚˜ë³´ë”ë¼êµ¬ìš”!?
ë‚¨í¸ê³¼ ì €, ë‘˜ ë‹¤ ë¹µëŸ¬ë²„ë¼ ì§€ë‚˜ì¹  ìˆ˜ ì—†ì–´ êµ¬ë§¤í•´ ë¨¹ì–´ë´¤ë‹µë‹ˆë‹¹ğŸ˜Š
ë³´ì„±ë…¹ì°¨íœ´ê²Œì†Œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì‹œë©´ ë”± ê°€ìš´ë° ìœ„ì¹˜í•´ ìˆì–´ìš”ã…ã…
ê·¸ë˜ì„œ ì–´ëŠ ë¬¸ìœ¼ë¡œë¼ë„ ë“¤ì–´ì˜¤ì…”ë„ ê°€ê¹ë‹µë‹ˆë‹¤ğŸ˜‰
ë©”ë‰´íŒì„ ì´ë ‡ê³ , ê°€ê²©ì€ 2000ì›~3000ì› ì‚¬ì´ì— í˜•ì„± ë˜ì–´ ìˆì–´ìš”!
ì´ëŸ°ê±° í•˜ë‚˜í•˜ë‚˜ ë§›ë³´ëŠ”ê±° ë„ˆë¬´ ì¢‹ì•„í•˜ëŠ”ë°... ì§„ì •í•˜ê³  ì†Œë¯¸ë¯¸ ë‹¨íŒ¥ë¹µ í•˜ë‚˜, ì˜¥ìˆ˜ìˆ˜ ì¹˜ì¦ˆë¹µ í•˜ë‚˜, êµ¬ë¦¬ë³¼ í•˜ë‚˜ ê³¨ëìŠµë‹ˆë‹¤!
ë‹¤ìŒì— ê°€ë©´ ê°•ë‚­ì½©ì´ë‘ ë°¤ ê¼­ ë¨¹ì–´ë´ì•¼ê² ì–´ìš”ğŸ˜™
```
The result of Kss is same with gold label. Especially it separates between `ê°€ê¹ë‹µë‹ˆë‹¤ğŸ˜‰` and `ë©”ë‰´íŒì„`.
In fact, that part is the final eomi (ì¢…ê²°ì–´ë¯¸), but many morpheme analyzers confuse the final eomi (ì¢…ê²°ì–´ë¯¸) with the connecting eomi (ì—°ê²°ì–´ë¯¸). 
Kss has a feature to recognize wrongly recognized connected eomi (ì—°ê²°ì–´ë¯¸). Thus, it was able to separate that domain effectively.
Next, Kss doesn't split between `ì¢‹ì•„í•˜ëŠ”ë°...` and `ì§„ì •í•˜ê³ `. it doesn't split sentences simply because `. ` appears. 
In most cases, `. ` could be the delimiter of sentences, 
but in fact there are many exceptions about this.

#### Example 2
- Input text
```
ì–´ëŠí™”ì°½í•œë‚  ì¶œê·¼ì „ì— ë„ˆë¬´ì¼ì°ì¼ì–´ë‚˜ ë²„ë ¸ìŒ (ì¶œê·¼ì‹œê°„ 19ì‹œ) í• êº¼ë„ì—†ê³ í•´ì„œ ì¹´í˜ë¥¼ ì°¾ì•„ ì‹œë‚´ë¡œ ë‚˜ê°”ìŒ ìƒˆë¡œìƒê¸´ê³³ì— ì‚¬ì¥ë‹˜ì´ ì»¤í”¼ì„ ìˆ˜ì¸ì§€ ì»¤í”¼ë°•ì‚¬ë¼ê³  í•´ì„œ ê°”ìŒ ì˜¤í”ˆí•œì§€ ì–¼ë§ˆì•ˆë˜ì„œ ê·¸ëŸ°ì§€ ì†ë‹˜ì´ ì–¼ë§ˆì—†ì—ˆìŒ ì¡°ìš©í•˜ê³  ì¢‹ë‹¤ë©° ì¢‹ì•„í•˜ëŠ”ê±¸ì‹œì¼œì„œ í…Œë¼ìŠ¤ì— ì•‰ìŒ ê·¼ë° ì¡°ìš©í•˜ë˜ ì¹´í˜ê°€ ì‚°ë§Œí•´ì§ ì†Œë¦¬ì˜ ì¶œì²˜ëŠ” ì¹´ìš´í„°ì˜€ìŒ(í…Œë¼ìŠ¤ê°€ ì¹´ìš´í„° ë°”ë¡œì˜†) ë“¤ì„ë¼ê³  ë“¤ì€ê²Œ ì•„ë‹ˆë¼ ê·€ëŠ” ì—´ë ¤ìˆìœ¼ë‹ˆ ë“£ê²Œëœ ëŒ€ì‚¬.
```
- Label
```
ì–´ëŠí™”ì°½í•œë‚  ì¶œê·¼ì „ì— ë„ˆë¬´ì¼ì°ì¼ì–´ë‚˜ ë²„ë ¸ìŒ (ì¶œê·¼ì‹œê°„ 19ì‹œ)
í• êº¼ë„ì—†ê³ í•´ì„œ ì¹´í˜ë¥¼ ì°¾ì•„ ì‹œë‚´ë¡œ ë‚˜ê°”ìŒ
ìƒˆë¡œìƒê¸´ê³³ì— ì‚¬ì¥ë‹˜ì´ ì»¤í”¼ì„ ìˆ˜ì¸ì§€ ì»¤í”¼ë°•ì‚¬ë¼ê³  í•´ì„œ ê°”ìŒ
ì˜¤í”ˆí•œì§€ ì–¼ë§ˆì•ˆë˜ì„œ ê·¸ëŸ°ì§€ ì†ë‹˜ì´ ì–¼ë§ˆì—†ì—ˆìŒ
ì¡°ìš©í•˜ê³  ì¢‹ë‹¤ë©° ì¢‹ì•„í•˜ëŠ”ê±¸ì‹œì¼œì„œ í…Œë¼ìŠ¤ì— ì•‰ìŒ
ê·¼ë° ì¡°ìš©í•˜ë˜ ì¹´í˜ê°€ ì‚°ë§Œí•´ì§
ì†Œë¦¬ì˜ ì¶œì²˜ëŠ” ì¹´ìš´í„°ì˜€ìŒ(í…Œë¼ìŠ¤ê°€ ì¹´ìš´í„° ë°”ë¡œì˜†)
ë“¤ì„ë¼ê³  ë“¤ì€ê²Œ ì•„ë‹ˆë¼ ê·€ëŠ” ì—´ë ¤ìˆìœ¼ë‹ˆ ë“£ê²Œëœ ëŒ€ì‚¬.
```
- Source
```
https://mrsign92.tistory.com/6099371
```
- Output texts
```
Baseline:

ì–´ëŠí™”ì°½í•œë‚  ì¶œê·¼ì „ì— ë„ˆë¬´ì¼ì°ì¼ì–´ë‚˜ ë²„ë ¸ìŒ (ì¶œê·¼ì‹œê°„ 19ì‹œ) í• êº¼ë„ì—†ê³ í•´ì„œ ì¹´í˜ë¥¼ ì°¾ì•„ ì‹œë‚´ë¡œ ë‚˜ê°”ìŒ ìƒˆë¡œìƒê¸´ê³³ì— ì‚¬ì¥ë‹˜ì´ ì»¤í”¼ì„ ìˆ˜ì¸ì§€ ì»¤í”¼ë°•ì‚¬ë¼ê³  í•´ì„œ ê°”ìŒ ì˜¤í”ˆí•œì§€ ì–¼ë§ˆì•ˆë˜ì„œ ê·¸ëŸ°ì§€ ì†ë‹˜ì´ ì–¼ë§ˆì—†ì—ˆìŒ ì¡°ìš©í•˜ê³  ì¢‹ë‹¤ë©° ì¢‹ì•„í•˜ëŠ”ê±¸ì‹œì¼œì„œ í…Œë¼ìŠ¤ì— ì•‰ìŒ ê·¼ë° ì¡°ìš©í•˜ë˜ ì¹´í˜ê°€ ì‚°ë§Œí•´ì§ ì†Œë¦¬ì˜ ì¶œì²˜ëŠ” ì¹´ìš´í„°ì˜€ìŒ(í…Œë¼ìŠ¤ê°€ ì¹´ìš´í„° ë°”ë¡œì˜†) ë“¤ì„ë¼ê³  ë“¤ì€ê²Œ ì•„ë‹ˆë¼ ê·€ëŠ” ì—´ë ¤ìˆìœ¼ë‹ˆ ë“£ê²Œëœ ëŒ€ì‚¬.
```

Baseline doesn't split any sentences because there's no `.!? ` in the input text.

```
Koalanlp (KKMA)

ì–´ëŠ í™”ì°½í•œ ë‚  ì¶œê·¼ ì „ì— ë„ˆë¬´ ì¼ì° ì¼ì–´ë‚˜ ë²„ë ¸ìŒ ( ì¶œê·¼ì‹œê°„ 19ì‹œ) í•  êº¼ë„ ì—†ê³  í•´ì„œ ì¹´í˜ë¥¼ ì°¾ì•„ ì‹œë‚´ë¡œ ë‚˜ê°”ìŒ ìƒˆë¡œ ìƒê¸´ ê³³ì— ì‚¬ì¥ë‹˜ì´ ì»¤í”¼ì„ ìˆ˜ì¸ì§€ ì»¤í”¼ë°•ì‚¬ë¼ê³  í•´ì„œ ê°”ìŒ ì˜¤í”ˆí•œì§€ ì–¼ë§ˆ ì•ˆ ë˜ ì„œ ê·¸ëŸ°ì§€ ì†ë‹˜ì´ ì–¼ë§ˆ ì—†ì—ˆìŒ ì¡°ìš©í•˜ê³  ì¢‹ë‹¤ë©° ì¢‹ì•„í•˜ëŠ” ê±¸ ì‹œì¼œì„œ í…Œë¼ìŠ¤ì— ì•‰ìŒ ê·¼ë° ì¡°ìš©í•˜ë˜ ì¹´í˜ê°€ ì‚°ë§Œ í•´ì§ ì†Œë¦¬ì˜ ì¶œì²˜ëŠ” ì¹´ìš´í„°ì˜€ìŒ( í…Œë¼ìŠ¤ê°€ ì¹´ìš´í„° ë°”ë¡œ ì˜†) ë“¤ì„ë¼ê³ 
ë“¤ì€ ê²Œ ì•„ë‹ˆë¼ ê·€ëŠ” ì—´ë ¤ ìˆìœ¼ë‹ˆ ë“£ê²Œ ëœ ëŒ€ì‚¬.
```

Koalanlp separates between `ë“¤ì„ë¼ê³ ` and `ë“¤ì€` but it is not correct split point.
And I think it doesn't consider predicative use of eomi transferred from noun (ëª…ì‚¬í˜• ì „ì„±ì–´ë¯¸ì˜ ì„œìˆ ì  ìš©ë²•).

```
Kiwi

ì–´ëŠí™”ì°½í•œë‚  ì¶œê·¼ì „ì— ë„ˆë¬´ì¼ì°ì¼ì–´ë‚˜ ë²„ë ¸ìŒ (ì¶œê·¼ì‹œê°„ 19ì‹œ) í• êº¼ë„ì—†ê³ í•´ì„œ ì¹´í˜ë¥¼ ì°¾ì•„ ì‹œë‚´ë¡œ ë‚˜ê°”ìŒ ìƒˆë¡œìƒê¸´ê³³ì— ì‚¬ì¥ë‹˜ì´ ì»¤í”¼ì„ ìˆ˜ì¸ì§€ ì»¤í”¼ë°•ì‚¬ë¼ê³  í•´ì„œ ê°”ìŒ ì˜¤í”ˆí•œì§€ ì–¼ë§ˆì•ˆë˜ì„œ ê·¸ëŸ°ì§€ ì†ë‹˜ì´ ì–¼ë§ˆì—†ì—ˆìŒ ì¡°ìš©í•˜ê³  ì¢‹ë‹¤ë©° ì¢‹ì•„í•˜ëŠ”ê±¸ì‹œì¼œì„œ í…Œë¼ìŠ¤ì— ì•‰ìŒ ê·¼ë° ì¡°ìš©í•˜ë˜ ì¹´í˜ê°€ ì‚°ë§Œí•´ì§ ì†Œë¦¬ì˜ ì¶œì²˜ëŠ” ì¹´ìš´í„°ì˜€ìŒ(í…Œë¼ìŠ¤ê°€ ì¹´ìš´í„° ë°”ë¡œì˜†) ë“¤ì„ë¼ê³  ë“¤ì€ê²Œ ì•„ë‹ˆë¼ ê·€ëŠ” ì—´ë ¤ìˆìœ¼ë‹ˆ ë“£ê²Œëœ ëŒ€ì‚¬.
```
Kiwi couldn't separate any sentences like baseline.
Similarly, it doesn't consider predicative use of eomi transferred from noun (ëª…ì‚¬í˜• ì „ì„±ì–´ë¯¸ì˜ ì„œìˆ ì  ìš©ë²•).

```
Kss (Mecab)

ì–´ëŠí™”ì°½í•œë‚  ì¶œê·¼ì „ì— ë„ˆë¬´ì¼ì°ì¼ì–´ë‚˜ ë²„ë ¸ìŒ (ì¶œê·¼ì‹œê°„ 19ì‹œ)
í• êº¼ë„ì—†ê³ í•´ì„œ ì¹´í˜ë¥¼ ì°¾ì•„ ì‹œë‚´ë¡œ ë‚˜ê°”ìŒ
ìƒˆë¡œìƒê¸´ê³³ì— ì‚¬ì¥ë‹˜ì´ ì»¤í”¼ì„ ìˆ˜ì¸ì§€ ì»¤í”¼ë°•ì‚¬ë¼ê³  í•´ì„œ ê°”ìŒ
ì˜¤í”ˆí•œì§€ ì–¼ë§ˆì•ˆë˜ì„œ ê·¸ëŸ°ì§€ ì†ë‹˜ì´ ì–¼ë§ˆì—†ì—ˆìŒ
ì¡°ìš©í•˜ê³  ì¢‹ë‹¤ë©° ì¢‹ì•„í•˜ëŠ”ê±¸ì‹œì¼œì„œ í…Œë¼ìŠ¤ì— ì•‰ìŒ
ê·¼ë° ì¡°ìš©í•˜ë˜ ì¹´í˜ê°€ ì‚°ë§Œí•´ì§ ì†Œë¦¬ì˜ ì¶œì²˜ëŠ” ì¹´ìš´í„°ì˜€ìŒ(í…Œë¼ìŠ¤ê°€ ì¹´ìš´í„° ë°”ë¡œì˜†)
ë“¤ì„ë¼ê³  ë“¤ì€ê²Œ ì•„ë‹ˆë¼ ê·€ëŠ” ì—´ë ¤ìˆìœ¼ë‹ˆ ë“£ê²Œëœ ëŒ€ì‚¬.
```
The result of Kss is very similar with gold label, Kss considers predicative use of eomi transferred from noun (ëª…ì‚¬í˜• ì „ì„±ì–´ë¯¸ì˜ ì„œìˆ ì  ìš©ë²•),
and has many exceptions to prevent mistakes. But Kss couldn't split sentences between `ì‚°ë§Œí•´ì§` and `ì†Œë¦¬ì˜`.
That part is correct split point, but it blocked by one of the exceptions which I built to prevent wrong segmentation.

#### 6) Speed analysis
I also measured speed of tools to compare their computation efficiency. The following table shows computation time of each tool when it splits `sample.txt` (41 sentences).
It is a single blog post, so you can expect the following time when you split a blog post into sentences.
Since the computation time may vary depending on the current CPU status, so I measured 5 times and calculated the average.
Note that every experiment was conducted on single thread / process environment with my M1 macbook pro (2021, 13'inch).

| Name           | Library version | Backend | Average time (msec) |
|----------------|-----------------|---------|---------------------|
| Baseline       | N/A             | N/A     | **0.22**            |
| koalanlp       | 2.1.7           | OKT     | 27.37               |
| koalanlp       | 2.1.7           | HNN     | 50.39               |
| koalanlp       | 2.1.7           | KMR     | 757.08              |
| koalanlp       | 2.1.7           | RHINO   | 978.53              |
| koalanlp       | 2.1.7           | EUNJEON | 881.24              |
| koalanlp       | 2.1.7           | ARIRANG | 1415.53             |
| koalanlp       | 2.1.7           | KAMA    | 1971.31             |
| Kiwi           | 0.14.0          | N/A     | 36.41               |
| **Kss (ours)** | 4.0.0           | pecab   | 6929.27             |
| **Kss (ours)** | 4.0.0           | mecab   | 43.80               |

You can also compare the speed of tools with the following graphs.

![](https://github.com/hyunwoongko/kss/blob/main/assets/average_computation_time.png)

You can also compare the speed of faster tools the following graphs (under 100 msec).

![](https://github.com/hyunwoongko/kss/blob/main/assets/average_computation_time_under_100.png)

The baseline was fastest (because it's a just regex function), and Koalanlp (OKT backend), Kiwi, Kss (mecab backend) were followed.
The slowest library was Kss (pecab backend) and it was about 160 times slower than its mecab backend.
Mecab and Kiwi were written in C++, All Koalanlp backends were written in Java and Pecab was written in pure python.
I think this difference was caused by speed of each language. Therefore, if you can install mecab, it makes most sense to use Kss Mecab backend.

- For Linux/MacOS users: Kss tries to install [`python-mecab-kor`](https://github.com/hyunwoongko/python-mecab-kor) when you install kss. so you can use mecab backend very easily.
But if it was failed, please install mecab yourself to use mecab backend.


- For Windows users: Kss supports [`mecab-ko-msvc`](https://github.com/Pusnow/mecab-ko-msvc) (mecab for Microsoft Visual C++), and its konlpy wrapper.
To use mecab backend, you need to install one of mecab and konlpy.tag.Mecab on your machine.
There are much information about mecab installing on Windows machine in internet like the following.
  - mecab: https://cleancode-ws.tistory.com/97
  - konlpy.tag.Mecab: https://uwgdqo.tistory.com/363

<br>

#### 7) Conclusion
I've measured the performance of Kss and other libraries using 6 evaluation datasets, and also measured their speed.
In terms of segmentation performance, Kss performed best on most datasets. In terms of speed, baseline was the fastest, and Koalanlp (OKT backend) and Kiwi followed. 
but Kss (mecab backend) also showed a speed that could compete with others.

However, there are still many difficulties and limitations in Korean sentence separation libraries, including Kss. 
In fact, it's also because very few people attack this task. 
If anyone wants to discuss Korean sentence segmentation algorithms with me or contribute to my work, 
feel free to send an email to kevin.ko@tunib.ai or let me know on the Github [issue](https://github.com/hyunwoongko/kss/issues) page.

</details>

<br>

#### 2) `split_morphemes`: split text into morphemes

```python
from kss import split_morphemes

split_morphemes(
    text: Union[str, List[str], Tuple[str]],
    backend: str = "auto",
    num_workers: Union[int, str] = "auto" 
)
```

<details>
<summary>Parameters</summary>

Note that the parameters of `split_morpehems` are exactly same with `split_sentences`.

- **text: String or List/Tuple of strings**
    - string: single text segmentation
    - list/tuple of strings: batch texts segmentation
- **backend: Morpheme analyzer backend.**
    - `backend='auto'`: find `mecab` â†’ `konlpy.tag.Mecab` â†’ `pecab` and use first found analyzer (default)
    - `backend='mecab'`: find `mecab` â†’ `konlpy.tag.Mecab` and use first found analyzer
    - `backend='pecab'`: use `pecab` analyzer
- **num_workers: The number of multiprocessing workers.**
    - `num_workers='auto'`: use multiprocessing with the maximum number of workers if possible (default)
    - `num_workers=1`: don't use multiprocessing
    - `num_workers=2~N`: use multiprocessing with the specified number of workers

</details>

<details>
<summary>Usages</summary>

- Single text segmentation
  ```python
  import kss

  text = "íšŒì‚¬ ë™ë£Œ ë¶„ë“¤ê³¼ ë‹¤ë…€ì™”ëŠ”ë° ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ìŒì‹ë„ ë§›ìˆì—ˆì–´ìš” ë‹¤ë§Œ, ê°•ë‚¨ í† ë¼ì •ì´ ê°•ë‚¨ ì‰‘ì‰‘ë²„ê±° ê³¨ëª©ê¸¸ë¡œ ì­‰ ì˜¬ë¼ê°€ì•¼ í•˜ëŠ”ë° ë‹¤ë“¤ ì‰‘ì‰‘ë²„ê±°ì˜ ìœ í˜¹ì— ë„˜ì–´ê°ˆ ë»” í–ˆë‹µë‹ˆë‹¤ ê°•ë‚¨ì—­ ë§›ì§‘ í† ë¼ì •ì˜ ì™¸ë¶€ ëª¨ìŠµ."

  kss.split_morphemes(text)
  # [('íšŒì‚¬', 'NNG'), (' ', 'SP'), ('ë™ë£Œ', 'NNG'), (' ', 'SP'), ('ë¶„', 'NNB'), ('ë“¤', 'XSN'), ('ê³¼', 'JKB'), (' ', 'SP'), ('ë‹¤ë…€ì™”', 'VV+EP'), ('ëŠ”ë°', 'EC'), (' ', 'SP'), ('ë¶„ìœ„ê¸°', 'NNG'), ('ë„', 'JX'), (' ', 'SP'), ('ì¢‹', 'VA'), ('ê³ ', 'EC'), (' ', 'SP'), ('ìŒì‹', 'NNG'), ('ë„', 'JX'), (' ', 'SP'), ('ë§›ìˆ', 'VA'), ('ì—ˆ', 'EP'), ('ì–´ìš”', 'EF'), (' ', 'SP'), ('ë‹¤ë§Œ', 'MAJ'), (',', 'SC'), (' ', 'SP'), ('ê°•ë‚¨', 'NNP'), (' ', 'SP'), ('í† ë¼', 'NNG'), ('ì •', 'NNG'), ('ì´', 'JKS'), (' ', 'SP'), ('ê°•ë‚¨', 'NNP'), (' ', 'SP'), ('ì‰‘ì‰‘', 'MAG'), ('ë²„ê±°', 'NNG'), (' ', 'SP'), ('ê³¨ëª©ê¸¸', 'NNG'), ('ë¡œ', 'JKB'), (' ', 'SP'), ('ì­‰', 'MAG'), (' ', 'SP'), ('ì˜¬ë¼ê°€', 'VV'), ('ì•¼', 'EC'), (' ', 'SP'), ('í•˜', 'VV'), ('ëŠ”ë°', 'EC'), (' ', 'SP'), ('ë‹¤', 'MAG'), ('ë“¤', 'XSN'), (' ', 'SP'), ('ì‰‘ì‰‘', 'MAG'), ('ë²„ê±°', 'NNG'), ('ì˜', 'JKG'), (' ', 'SP'), ('ìœ í˜¹', 'NNG'), ('ì—', 'JKB'), (' ', 'SP'), ('ë„˜ì–´ê°ˆ', 'VV+ETM'), (' ', 'SP'), ('ë»”', 'NNB'), (' ', 'SP'), ('í–ˆ', 'VV+EP'), ('ë‹µë‹ˆë‹¤', 'EC'), (' ', 'SP'), ('ê°•ë‚¨ì—­', 'NNP'), (' ', 'SP'), ('ë§›ì§‘', 'NNG'), (' ', 'SP'), ('í† ë¼', 'NNG'), ('ì •ì˜', 'NNG'), (' ', 'SP'), ('ì™¸ë¶€', 'NNG'), (' ', 'SP'), ('ëª¨ìŠµ', 'NNG'), ('.', 'SF')]
  ```

- Batch texts segmentation
  ```python
  import kss

  texts = [
      "íšŒì‚¬ ë™ë£Œ ë¶„ë“¤ê³¼ ë‹¤ë…€ì™”ëŠ”ë° ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ìŒì‹ë„ ë§›ìˆì—ˆì–´ìš” ë‹¤ë§Œ, ê°•ë‚¨ í† ë¼ì •ì´ ê°•ë‚¨ ì‰‘ì‰‘ë²„ê±° ê³¨ëª©ê¸¸ë¡œ ì­‰ ì˜¬ë¼ê°€ì•¼ í•˜ëŠ”ë° ë‹¤ë“¤ ì‰‘ì‰‘ë²„ê±°ì˜ ìœ í˜¹ì— ë„˜ì–´ê°ˆ ë»” í–ˆë‹µë‹ˆë‹¤",
      "ê°•ë‚¨ì—­ ë§›ì§‘ í† ë¼ì •ì˜ ì™¸ë¶€ ëª¨ìŠµ. ê°•ë‚¨ í† ë¼ì •ì€ 4ì¸µ ê±´ë¬¼ ë…ì±„ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.",
      "ì—­ì‹œ í† ë¼ì • ë³¸ ì  ë‹µì£ ?ã…ã……ã… ê±´ë¬¼ì€ í¬ì§€ë§Œ ê°„íŒì´ ì—†ê¸° ë•Œë¬¸ì— ì§€ë‚˜ì¹  ìˆ˜ ìˆìœ¼ë‹ˆ ì¡°ì‹¬í•˜ì„¸ìš” ê°•ë‚¨ í† ë¼ì •ì˜ ë‚´ë¶€ ì¸í…Œë¦¬ì–´.",
  ]

  kss.split_morphemes(texts)
  # [[('íšŒì‚¬', 'NNG'), (' ', 'SP'), ('ë™ë£Œ', 'NNG'), (' ', 'SP'), ('ë¶„', 'NNB'), ('ë“¤', 'XSN'), ('ê³¼', 'JKB'), (' ', 'SP'), ('ë‹¤ë…€ì™”', 'VV+EP'), ('ëŠ”ë°', 'EC'), (' ', 'SP'), ('ë¶„ìœ„ê¸°', 'NNG'), ('ë„', 'JX'), (' ', 'SP'), ('ì¢‹', 'VA'), ('ê³ ', 'EC'), (' ', 'SP'), ('ìŒì‹', 'NNG'), ('ë„', 'JX'), (' ', 'SP'), ('ë§›ìˆ', 'VA'), ('ì—ˆ', 'EP'), ('ì–´ìš”', 'EF'), (' ', 'SP'), ('ë‹¤ë§Œ', 'MAJ'), (',', 'SC'), (' ', 'SP'), ('ê°•ë‚¨', 'NNP'), (' ', 'SP'), ('í† ë¼', 'NNG'), ('ì •', 'NNG'), ('ì´', 'JKS'), (' ', 'SP'), ('ê°•ë‚¨', 'NNP'), (' ', 'SP'), ('ì‰‘ì‰‘', 'MAG'), ('ë²„ê±°', 'NNG'), (' ', 'SP'), ('ê³¨ëª©ê¸¸', 'NNG'), ('ë¡œ', 'JKB'), (' ', 'SP'), ('ì­‰', 'MAG'), (' ', 'SP'), ('ì˜¬ë¼ê°€', 'VV'), ('ì•¼', 'EC'), (' ', 'SP'), ('í•˜', 'VV'), ('ëŠ”ë°', 'EC'), (' ', 'SP'), ('ë‹¤', 'MAG'), ('ë“¤', 'XSN'), (' ', 'SP'), ('ì‰‘ì‰‘', 'MAG'), ('ë²„ê±°', 'NNG'), ('ì˜', 'JKG'), (' ', 'SP'), ('ìœ í˜¹', 'NNG'), ('ì—', 'JKB'), (' ', 'SP'), ('ë„˜ì–´ê°ˆ', 'VV+ETM'), (' ', 'SP'), ('ë»”', 'NNB'), (' ', 'SP'), ('í–ˆ', 'VV+EP'), ('ë‹µë‹ˆë‹¤', 'EC')], 
  # [('ê°•ë‚¨ì—­', 'NNP'), (' ', 'SP'), ('ë§›ì§‘', 'NNG'), (' ', 'SP'), ('í† ë¼', 'NNG'), ('ì •ì˜', 'NNG'), (' ', 'SP'), ('ì™¸ë¶€', 'NNG'), (' ', 'SP'), ('ëª¨ìŠµ', 'NNG'), ('.', 'SF'), (' ', 'SP'), ('ê°•ë‚¨', 'NNP'), (' ', 'SP'), ('í† ë¼', 'NNG'), ('ì •ì€', 'NNP'), (' ', 'SP'), ('4', 'SN'), ('ì¸µ', 'NNG'), (' ', 'SP'), ('ê±´ë¬¼', 'NNG'), (' ', 'SP'), ('ë…ì±„', 'NNG'), ('ë¡œ', 'JKB'), (' ', 'SP'), ('ì´ë£¨ì–´ì ¸', 'VV+EC'), (' ', 'SP'), ('ìˆ', 'VX'), ('ìŠµë‹ˆë‹¤', 'EF'), ('.', 'SF')], 
  # [('ì—­ì‹œ', 'MAJ'), (' ', 'SP'), ('í† ë¼', 'NNG'), ('ì •', 'NNG'), (' ', 'SP'), ('ë³¸', 'VV+ETM'), (' ', 'SP'), ('ì ', 'NNB'), (' ', 'SP'), ('ë‹µ', 'MAG+VCP'), ('ì£ ', 'EF'), ('?', 'SF'), ('ã…', 'IC'), ('ã……', 'NNG'), ('ã…', 'IC'), (' ', 'SP'), ('ê±´ë¬¼', 'NNG'), ('ì€', 'JX'), (' ', 'SP'), ('í¬', 'VA'), ('ì§€ë§Œ', 'EC'), (' ', 'SP'), ('ê°„íŒ', 'NNG'), ('ì´', 'JKS'), (' ', 'SP'), ('ì—†', 'VA'), ('ê¸°', 'ETN'), (' ', 'SP'), ('ë•Œë¬¸', 'NNB'), ('ì—', 'JKB'), (' ', 'SP'), ('ì§€ë‚˜ì¹ ', 'VV+ETM'), (' ', 'SP'), ('ìˆ˜', 'NNB'), (' ', 'SP'), ('ìˆ', 'VV'), ('ìœ¼ë‹ˆ', 'EC'), (' ', 'SP'), ('ì¡°ì‹¬', 'NNG'), ('í•˜', 'XSV'), ('ì„¸ìš”', 'EP+EF'), (' ', 'SP'), ('ê°•ë‚¨', 'NNP'), (' ', 'SP'), ('í† ë¼', 'NNG'), ('ì •ì˜', 'NNG'), (' ', 'SP'), ('ë‚´ë¶€', 'NNG'), (' ', 'SP'), ('ì¸í…Œë¦¬ì–´', 'NNG'), ('.', 'SF')]]
  ```

</details>

<br>

## Kss in various programming languages
Kss is available in various programming languages.
- [Kss Python version](https://github.com/hyunwoongko/kss)
- [Kss Java version](https://github.com/sangdee/kss-java)
- [Kss Flutter version](https://github.com/khjde1207/kss_dart)
- [Kss C++ version](https://github.com/likejazz/korean-sentence-splitter)

## Citation
If you find this toolkit useful, please consider citing:
```
@misc{kss,
  author       = {Ko, Hyunwoong and Park, Sang-kil},
  title        = {Kss: A Toolkit for Korean sentence segmentation},
  howpublished = {\url{https://github.com/hyunwoongko/kss}},
  year         = {2021},
}
```

## License
Kss project is licensed under the terms of the BSD 3-Clause "New" or "Revised" License.

Copyright 2021 [Hyunwoong Ko](https://github.com/hyunwoongko) and [Sang-kil Park](https://github.com/likejazz). All Rights Reserved.
